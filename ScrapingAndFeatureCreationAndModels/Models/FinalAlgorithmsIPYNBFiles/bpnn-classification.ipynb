{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom keras.layers import Dense, Dropout\nfrom tensorflow.keras import layers\nfrom keras.layers import Activation\nfrom keras.models import Sequential\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimport tensorflow as tf\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, make_scorer\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom math import sqrt\nimport traceback\nfrom multiprocessing.pool import ThreadPool\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_process_data(data,null_threshold):\n    \"\"\"\n    Drops Date and Unix Date columns from the data.\n    Drops the columns which has null values more than specified null_threshold.\n    Replaces infinite values with NAN.\n    Drops the rows which has null values.\n\n    Parameters\n    ----------\n    data : dataframe\n\n    null_threshold : numeric\n        numeric value describing the amount of null values that can be present.\n\n    Returns\n    -------\n    data : dataframe\n        an updated dataframe after performing all the opertaions.\n    \"\"\"\n    \n    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n    total = data.shape[0]\n    for col in data.columns:\n        if null_threshold * total / 100 < data[col].isnull().sum():\n            data.drop(columns=[col],axis=1,inplace=True)\n    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n    data = data.apply(pd.to_numeric,errors='coerce')\n    data.dropna(axis=0,inplace=True)\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dependent_column(data,column):\n    \"\"\"\n    Removes all the Next Day columns.\n    Removes all the non Growth Rate Columns (GR)\n    add the predictor column to list of columns.\n\n    Parameters\n    ----------\n    data : dataframe\n\n    column : string\n        name of the predictor column \n\n    Returns\n    -------\n    data : dataframe\n        an updated dataframe after performing all the opertaions.\n    column : string\n        name of the predictor column\n    \"\"\"\n    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n    cols.append(column)\n    data = data[cols]\n    return (data,column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def error_metrics(y_true, y_pred):\n    rmse = sqrt(metrics.mean_squared_error(y_true, y_pred))\n    mae = metrics.mean_absolute_error(y_true, y_pred)\n    mse = metrics.mean_squared_error(y_true, y_pred)\n    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_confusion_matrix(y_true,y_pred):\n    \n    cm = confusion_matrix(y_true,y_pred)\n    accuracy = metrics.accuracy_score(y_true,y_pred)\n    precision = metrics.precision_score(y_true,y_pred)\n    recall = metrics.recall_score(y_true,y_pred)\n    f1_score = metrics.f1_score(y_true,y_pred)\n    return {\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall,\"f1_score\":f1_score,\"confusion matrix\":cm}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\ndef f1_score(y_true, y_pred):\n    def recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_b(input_dim,layers=3,units = 32):\n    model = Sequential()\n    model.add(Dense(units=units,input_dim=(input_dim),activation = 'relu'))\n    model.add(Dense(units=units,activation = 'relu'))\n    model.add(Dense(units = 1,activation = 'sigmoid'))\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=tf.keras.metrics.Precision())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def best_params_bpnn(X,Y):\n    custom_scorer = make_scorer(metrics.precision_score, greater_is_better=True,pos_label = 1)\n    \n    input_dim = X.shape[1]\n    X = np.array(X)\n    X = np.reshape(X,(X.shape[0],X.shape[1]))\n    Y = np.array(Y)\n    Y = np.reshape(Y,(Y.shape[0],1))\n    \n    model = KerasClassifier(build_fn = create_model_b,input_dim = input_dim,verbose=0) \n    \n    batch_size = [25,32]\n    epochs = [25,50]\n    param_grid = dict(epochs=epochs,batch_size=batch_size)   \n    \n    grid = GridSearchCV(estimator=model, param_grid=param_grid,n_jobs=-1,scoring=custom_scorer,verbose=1,refit=\"precision_score\")\n    grid_result = grid.fit(X,Y)\n    batch_size, epochs = grid_result.best_params_['batch_size'],grid_result.best_params_['epochs']\n    \n    return batch_size, epochs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_bpnn_classification(df,column,epochs,batch_size,rate):\n    df[\"Target\"] = df[column].apply(lambda x : 1 if x >= rate else 0)\n    X = df.drop(columns=[\"Target\",column])\n    Y = df[\"Target\"]\n    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state = 0)\n    input_dim = x_train.shape[1]\n\n    x_train = np.array(x_train)\n    x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1]))\n    x_test = np.array(x_test)\n    x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1]))\n    y_test = np.array(y_test)\n    y_test = np.reshape(y_test,(y_test.shape[0],1))\n    \n#     model = KerasClassifier(build_fn = create_model_b, batch_size=batch_size, epochs=epochs,input_dim = input_dim) \n    model = create_model_b(input_dim)\n    history = model.fit(x_train,y_train,epochs = epochs,batch_size = batch_size, validation_data = (x_test,y_test),shuffle = False,verbose=0)\n    result = {}\n\n    y_pred = model.predict(x_test)\n    y_pred = np.array(y_pred)\n    \n    result.update({'actual':y_test,'pred':y_pred})\n    y_pred = np.reshape(y_pred,(y_pred.shape[0],1)).round()\n    \n    error = error_metrics(y_test, y_pred)\n    confusion = create_confusion_matrix(y_test,y_pred)\n    result.update(error)\n    result.update(confusion)\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bpnn_classification(df, column = \"Next Day Close Price GR\"):\n    rate_of_growth = [0.001,0.002,0.003,0.004,0.005]\n    solution = list()\n    for t in rate_of_growth:\n        df[\"Target\"] = df[column].apply(lambda x : 1 if x >= t else 0)\n        X = df.drop(columns=[\"Target\",column])\n        Y = df[\"Target\"]\n        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n        batch_size, epochs = best_params_bpnn(X_train,y_train)\n        result = create_bpnn_classification(df,column = \"Next Day Close Price GR\",epochs = epochs,batch_size = batch_size,rate = t)\n        result.update({\"batch_size\":batch_size,\"epochs\":epochs,\"rate_of_growth\":t})\n        solution.append(result)\n    return solution","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"security_codes = list()\nfor filename in os.listdir(\"../input/newdata/grstocks\"):\n    security_codes.append(filename[2:-4])\nsecurity_codes.sort()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor name in security_codes:\n    try:\n        print(name)\n        df = pd.read_csv(os.path.join(\"../input/newdata/grstocks/\",\"gr\"+str(name)+\".csv\"))\n        df = pre_process_data(df,60)\n        df,column = dependent_column(df, column = \"Next Day Close Price GR\")\n        bpnn_res = bpnn_classification(df)\n        bpnn_df = pd.DataFrame(bpnn_res)\n        bpnn_df.to_csv('bpnn_'+str(name)+\".csv\",index=None)\n    except Exception as e:\n        traceback.print_exc() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}