{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom math import sqrt\nfrom sklearn.model_selection import GridSearchCV\nimport time \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.metrics import confusion_matrix\nimport math\nfrom sklearn.metrics import precision_score, make_scorer\nimport traceback\nimport io","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputpath = \"/kaggle/input/stockdata\"\ninputpath","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_process_data(data,null_threshold):\n    \"\"\"\n    Drops Date and Unix Date columns from the data.\n    Drops the columns which has null values more than specified null_threshold.\n    Replaces infinite values with NAN.\n    Drops the rows which has null values.\n\n    Parameters\n    ----------\n    data : dataframe\n\n    null_threshold : numeric\n        numeric value describing the amount of null values that can be present.\n\n    Returns\n    -------\n    data : dataframe\n        an updated dataframe after performing all the opertaions.\n    \"\"\"\n    \n    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n    total = data.shape[0]\n    for col in data.columns:\n        if null_threshold * total / 100 < data[col].isnull().sum():\n            data.drop(columns=[col],axis=1,inplace=True)\n    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n    data.dropna(axis=0,inplace=True)\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dependent_column(data,column):\n    \"\"\"\n    Removes all the Next Day columns.\n    Removes all the non Growth Rate Columns (GR)\n    add the predictor column to list of columns.\n\n    Parameters\n    ----------\n    data : dataframe\n\n    column : string\n        name of the predictor column \n\n    Returns\n    -------\n    data : dataframe\n        an updated dataframe after performing all the opertaions.\n    column : string\n        name of the predictor column\n    \"\"\"\n    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n    cols.append(column)\n    data = data[cols]\n    return (data,column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def best_params_logistic(X,Y):\n    custom_scorer = make_scorer(metrics.f1_score, greater_is_better=True,pos_label = 1)\n    penalty = ['l1', 'l2','none']\n    C = [0.001,0.01,0.1,1,10,100]\n    hyperparameters = dict(C = C, penalty = penalty)\n    logistic = LogisticRegression()\n    try:\n        gridsearch = GridSearchCV(logistic, hyperparameters, cv=5,verbose=0,scoring = custom_scorer)\n        best_model = gridsearch.fit(X, Y)\n    except:\n        hyperparameters[\"penalty\"] = ['none','l2']\n        gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0,scoring = custom_scorer)\n        best_model = gridsearch.fit(X, Y)\n    best_p = best_model.best_estimator_.get_params()[\"penalty\"]\n    best_c = best_model.best_estimator_.get_params()[\"C\"]\n    return best_p,best_c","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def error_metrics(y_true, y_pred):\n    rmse = sqrt(metrics.mean_squared_error(y_true, y_pred))\n    mae = metrics.mean_absolute_error(y_true, y_pred)\n    mse = metrics.mean_squared_error(y_true, y_pred)\n    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_confusion_matrix(y_true,y_pred):\n    \n    cm = confusion_matrix(y_true,y_pred)\n    accuracy = metrics.accuracy_score(y_true,y_pred)\n    precision = metrics.precision_score(y_true,y_pred)\n    recall = metrics.recall_score(y_true,y_pred)\n    f1_score = metrics.f1_score(y_true,y_pred)\n    return {\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall,\"f1_score\":f1_score,\"confusion matrix\":cm}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_logistic_model(df,column, rate,C, penalty):\n    df[\"Target\"] = df[\"Next Day Close Price GR\"].apply(lambda x : 1 if x >= rate else 0)\n    X = df.drop(columns=[\"Target\",column])\n    Y = df[\"Target\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n    logmodel = LogisticRegression(penalty = penalty, C = C,random_state = 0)\n    logmodel.fit(X_train, y_train)\n    y_pred = logmodel.predict(X_test)\n    \n    result = {}\n    error = error_metrics(y_test, y_pred)\n    confusion = create_confusion_matrix(y_test,y_pred)\n    result.update(error)\n    result.update(confusion)\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def logistic_model(df,column = \"Next Day Close Price GR\"):\n    \n    rate_of_growth = [0.001,0.002,0.003,0.004,0.005]\n    solution = list()\n    for t in rate_of_growth:\n        df[\"Target\"] = df[\"Next Day Close Price GR\"].apply(lambda x : 1 if x >= t else 0)\n        X = df.drop(columns=[\"Target\",column])\n        Y = df[\"Target\"]\n\n        P_values = [0.01,0.05,0.1,0.15,0.2,0.25]\n        F_values = [0.1,0.5,1,2,5,10,100]\n\n        f_col_values, p_col_values = f_classif(X,Y)\n        f_col_values = dict(zip(X.columns,f_col_values))\n        p_col_values = dict(zip(X.columns,p_col_values))\n        \n        for p in P_values:\n            mycols = list()\n            for col,val in p_col_values.items():\n                if val <= p:\n                    mycols.append(col)\n            if mycols == []:\n                continue\n            X = df[mycols]\n            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n            best_p,best_c = best_params_logistic(X_train,y_train)\n            result = create_logistic_model(df,column = \"Next Day Close Price GR\",rate = t,C = best_c, penalty = best_p)\n            result.update({\"penalty\":best_p,\"C\":best_c,\"p_f_value\":\"p_\"+str(p),\"rate_of_growth\":t})\n            result.update({\"features\":mycols})\n            solution.append(result)\n\n        for f in F_values:\n            mycols = list()\n            for col,val in f_col_values.items():\n                if val >= f:\n                    mycols.append(col)\n            if mycols == []:\n                continue\n            X = df[mycols]\n            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n            best_p,best_c = best_params_logistic(X_train,y_train)\n            result = create_logistic_model(df,column = \"Next Day Close Price GR\",rate = t,C = best_c, penalty = best_p)\n            result.update({\"penalty\":best_p,\"C\":best_c,\"p_f_value\":\"f_\"+str(f),\"rate_of_growth\":t})\n            result.update({\"features\":mycols})\n            solution.append(result)\n\n    return solution","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"security_codes = list()\nfor filename in os.listdir(\"../input/newdata/grstocks\"):\n    security_codes.append(filename[2:-4])\nsecurity_codes.sort()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name in security_codes:\n    try:\n        print(name)\n        df = pd.read_csv(os.path.join(\"../input/newdata/grstocks/\",\"gr\"+str(name)+\".csv\"))\n        df = pre_process_data(df,60)\n        column = \"Next Day Close Price GR\"\n        df,column = dependent_column(df,column)\n        result = logistic_model(df,column)\n        result_df = pd.DataFrame(result)\n        result_df.to_csv(\"logistic_\"+str(name)+\".csv\",index=None)\n    except Exception as e:\n        traceback.print_exc() ","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}